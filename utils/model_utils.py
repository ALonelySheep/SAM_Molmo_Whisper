"""
Model forward passes and other model processing utilities.
"""

from transformers import GenerationConfig

import torch
import numpy as np

def get_molmo_output(image, processor, model, prompt='Describe this image.'):
    """
    Function to get output from Molmo model given an image and a prompt.

    :param image: PIL image.
    :param prompt: User prompt.

    Returns:
        generated_text: Output generated by the model.
    """
    inputs = processor.process(images=[image], text=prompt)
    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}
    
    output = model.generate_from_batch(
        inputs,
        GenerationConfig(max_new_tokens=200, stop_strings='<|endoftext|>'),
        tokenizer=processor.tokenizer
    )
    
    generated_tokens = output[0, inputs['input_ids'].size(1):]
    generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)
    
    return generated_text

def get_sam_output(image, model, input_points, input_labels):
    """
    Function to predict SAM output.

    :param image: Numpy array image.
    :param input_points: 2D coordinates in form [(x, y), (x, y), ...]
    :param input_labels: Array of 0 or 1 for each 2D coordinate indicating
        negative and positive prompts, format => [1, 1, 1, 0, 1, 0]

    Returns:
        masks: The segmentation mask.
        scores: Scores for the masks.
        logits: Model mask logits.
        sorted_ind: Mask indices sorted according to score. 
    """
    # with torch.no_grad():
    with torch.inference_mode(), torch.autocast(device_type='cuda'):
        model.set_image(image)
        masks, scores, logits = model.predict(
            point_coords=input_points,
            point_labels=input_labels,
            multimask_output=True,
        )
    
    # Sort masks by score.
    sorted_ind = np.argsort(scores)[::-1]
    masks = masks[sorted_ind]
    scores = scores[sorted_ind]

    return masks, scores, logits, sorted_ind

def get_whisper_output(audio, model):
    """
    Function to get audio transcription from Whisper.

    :param audio: Audio file or recorded audio from Gradio microphone input.

    Returns:
        transcripted_text: The transcripted text from Whisper.
        prompt: The updated prompt.
    """
    sr, y = audio
    # Convert to mono if stereo
    if y.ndim > 1:
        y = y.mean(axis=1)

    y = y.astype(np.float32)
    y /= np.max(np.abs(y))

    transcribed_text = model({'sampling_rate': sr, 'raw': y})['text'] 
    prompt = transcribed_text

    return transcribed_text, prompt